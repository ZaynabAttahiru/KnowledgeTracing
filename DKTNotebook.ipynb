{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DKTNotebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNbHnmwpb3Qu1dgWONpolGf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZaynabAttahiru/KnowledgeTracing/blob/main/DKTNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deep Knowledge Tracing\n",
        "\n",
        "Deep Knowledge Tracing (DKT) is an application of the Long Short-Term Memory architecture as a model for tracing student's knowledge as they interact with coursework. In the basic form of DKT, the students' interaction is represented as a tuple of question and answer set `x = {xq,xa}`.\n",
        "\n",
        "In this notebook, we will be implementing the basic model of DKT on a couple of datasets. Later on we will we try and apply a distributed learning approach"
      ],
      "metadata": {
        "id": "AHDaLiK-8FRa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Model\n",
        "\n",
        "In this section, we will define a basic RNN model with the architecture of an LSTM in PyTorch. This code was adapted from [this Github repository](https://github.com/chsong513/DeepKnowledgeTracing-DKT-Pytorch).\n",
        "First, we will install the dependencies necessary for this codebase to work - PyTorch as well as the federated learning framework, [Flower](https://flower.dev).\n",
        "Additionally we will download the dataset required to run the model in this notebook."
      ],
      "metadata": {
        "id": "0EGLJoRL4_9z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch\n",
        "!pip install flwr==0.17.0\n",
        "!curl https://raw.githubusercontent.com/ZaynabAttahiru/KnowledgeTracing/main/data_test.csv > ./sample_data/data_train.csv\n",
        "!curl https://raw.githubusercontent.com/ZaynabAttahiru/KnowledgeTracing/main/data_train.csv > ./sample_data/data_test.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Be2Xhkui6iZb",
        "outputId": "99396db5-13eb-4a00-b585-8b2f25da8c2b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.10.0+cu111)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Collecting flwr==0.17.0\n",
            "  Downloading flwr-0.17.0-py3-none-any.whl (229 kB)\n",
            "\u001b[K     |████████████████████████████████| 229 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<4.0.0,>=3.12.1 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (3.17.3)\n",
            "Requirement already satisfied: google<3.0.0,>=2.0.3 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (2.0.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.27.2 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (1.43.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.19.0 in /usr/local/lib/python3.7/dist-packages (from flwr==0.17.0) (1.19.5)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from google<3.0.0,>=2.0.3->flwr==0.17.0) (4.6.3)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.7/dist-packages (from grpcio<2.0.0,>=1.27.2->flwr==0.17.0) (1.15.0)\n",
            "Installing collected packages: flwr\n",
            "Successfully installed flwr-0.17.0\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  590k  100  590k    0     0  2278k      0 --:--:-- --:--:-- --:--:-- 2278k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2033k  100 2033k    0     0  6374k      0 --:--:-- --:--:-- --:--:-- 6354k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Swcscdir74lL",
        "outputId": "0e64cd9b-65e2-4bed-8a07-9bc398a957c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dktmodel.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile dktmodel.py\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "\n",
        "class DKTModel(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, device):\n",
        "    super(DKTModel, self).__init__()\n",
        "    self.hidden_dim = hidden_dim\n",
        "    self.layer_dim = layer_dim\n",
        "    self.output_dim = output_dim\n",
        "    self.rnn = nn.RNN(input_dim, hidden_dim, layer_dim, batch_first = True, nonlinearity='tanh')\n",
        "    self.fc = nn.Linear(self.hidden_dim, self.output_dim)\n",
        "    self.sig = nn.Sigmoid()\n",
        "    self.device = device\n",
        "\n",
        "  def forward(self,x):\n",
        "    h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
        "    out, hn = self.rnn(x, h0)\n",
        "    result = self.sig(self.fc(out))\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Handling the Data\n",
        "\n",
        "We will now define a script that includes the helper functions that will handle all the data manipulations required to run the model defined above. This will include defining the students' interactions as one-hot encodings."
      ],
      "metadata": {
        "id": "1jskIf_l-b5a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile dataloader.py\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data as Data\n",
        "import itertools\n",
        "\n",
        "\"\"\"Reading the dataset\"\"\"\n",
        "def getData(path, num_of_questions, max_step, data_type):\n",
        "  print('loading ' + data_type +  ' data...')\n",
        "  trace_data = []\n",
        "  with open(path, 'r') as file:\n",
        "    for len, ques, ans in itertools.zip_longest(*[file] * 3):\n",
        "      len = int(len.strip().strip(','))\n",
        "      ques = [int(q) for q in ques.strip().strip(',').split(',')]\n",
        "      ans = [int(a) for a in ans.strip().strip(',').split(',')]\n",
        "      slices = len//max_step + (1 if len % max_step > 0 else 0)\n",
        "\n",
        "      for i in range(slices):\n",
        "         temp = temp = np.zeros(shape=[max_step, 2 * num_of_questions])\n",
        "         if len > 0:\n",
        "           if len >= max_step:\n",
        "             steps = max_step\n",
        "           else:\n",
        "             steps = len\n",
        "           for j in range(steps):\n",
        "             if ans[i*max_step + j] == 1:\n",
        "                temp[j][ques[i*max_step + j]] = 1\n",
        "             else:\n",
        "                temp[j][ques[i*max_step + j] + num_of_questions] = 1\n",
        "           len = len - max_step\n",
        "\n",
        "         trace_data.append(temp.tolist())\n",
        "    print('done: ' + str(np.array(trace_data).shape))\n",
        "    return np.array(trace_data)\n",
        "\n",
        "\"\"\"Load the dataset\"\"\"\n",
        "def getDataLoader(batch_size, num_of_questions, max_step):\n",
        "  train_data = torch.tensor(getData('sample_data/data_train.csv', num_of_questions, max_step, 'train').astype(float).tolist(),\n",
        "                            dtype=torch.float32)\n",
        "  test_data = torch.tensor(getData('sample_data/data_test.csv', num_of_questions, max_step, 'test').astype(float).tolist(),\n",
        "                            dtype=torch.float32)\n",
        "  trainloader = Data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "  testloader = Data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "  num_examples = {\"trainset\": len(trainloader), \"testset\": len(testloader)}\n",
        "\n",
        "  return trainloader, testloader\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_nDQRRi-9Fp",
        "outputId": "d682fc35-a95b-48ef-af0c-a75fb130d6b2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting dataloader.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next up, we will write a script that will contain the functions that will be used to evaluate our model against the dataset."
      ],
      "metadata": {
        "id": "-akpM_LbJzZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile eval.py\n",
        "\n",
        "import tqdm\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from sklearn import metrics\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def performance(ground_truth, prediction):\n",
        "  grtruth = ground_truth.detach().cpu().numpy()\n",
        "  predict = torch.round(prediction).detach().cpu().numpy()\n",
        "\n",
        "  fpr, tpr, thresholds = metrics.roc_curve(grtruth, prediction.detach().cpu().numpy())\n",
        "  auc = metrics.auc(fpr,tpr)\n",
        "\n",
        "  f1 = metrics.f1_score(grtruth, predict)\n",
        "  recall = metrics.recall_score(grtruth, predict)\n",
        "  precision = metrics.precision_score(grtruth, predict)\n",
        "\n",
        "  print('auc: ' + str(auc) + ' f1: ' + str(f1) + ' recall: ' + str(recall) + ' precision: ' + str(precision) + '\\n')\n",
        "  return auc, recall\n",
        "\n",
        "\n",
        "class lossFunc(nn.Module):\n",
        "  def __init__(self, num_of_questions, max_step, device):\n",
        "    super(lossFunc, self).__init__()\n",
        "    self.crossEntropy = nn.BCELoss()\n",
        "    self.num_of_questions = num_of_questions\n",
        "    self.max_step = max_step\n",
        "    self.device = device\n",
        "\n",
        "  def forward(self, pred, batch):\n",
        "    loss = 0\n",
        "    prediction = torch.Tensor([], device=self.device)\n",
        "    ground_truth = torch.Tensor([], device=self.device)\n",
        "\n",
        "    for student in range(pred.shape[0]):\n",
        "      delta = batch[student][:,0:self.num_of_questions] + batch[\n",
        "              student][:,self.num_of_questions:]\n",
        "      temp = pred[student][:self.max_step - 1].mm(delta[1:].t())\n",
        "      index = torch.tensor([[i for i in range(self.max_step - 1)]],\n",
        "                                 dtype=torch.long, device=self.device)\n",
        "      p = temp.gather(0, index)[0]\n",
        "      a = (((batch[student][:, 0:self.num_of_questions] -\n",
        "                   batch[student][:, self.num_of_questions:]).sum(1) + 1) //\n",
        "                 2)[1:]\n",
        "      for i in range(len(p) - 1, -1, -1):\n",
        "        if p[i] > 0:\n",
        "          p = p[:i + 1]\n",
        "          a = a[:i + 1]\n",
        "          break\n",
        "      loss += self.crossEntropy(p, a)\n",
        "      prediction = torch.cat([prediction, p])\n",
        "      ground_truth = torch.cat([ground_truth, a])\n",
        "    return loss, prediction, ground_truth\n",
        "\n",
        "\n",
        "\"\"\"Defining the train and test functions\"\"\"\n",
        "\n",
        "def train(model, trainloader, optimizer, loss_func, device):\n",
        "  model.to(device)\n",
        "  for batch in tqdm.tqdm(trainloader, desc='Training: ', mininterval=2):\n",
        "    batch = batch.to(device)\n",
        "    pred = model(batch)\n",
        "    loss, prediction, ground_truth = loss_func(pred, batch)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  return model, optimizer\n",
        "\n",
        "\n",
        "def train_epoch(model, trainloader, loss_func, device, start_epoch, end_epoch, log_progress):\n",
        "  optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
        "\n",
        "  print(f\"Training from epoch(s) {start_epoch} to {end_epoch} w/ {len(trainloader)} batches each.\", flush=True)\n",
        "  results = []\n",
        "\n",
        "  for epoch in range(start_epoch, end_epoch+1):\n",
        "    ground_truth = torch.Tensor([], device=device)\n",
        "    prediction = torch.Tensor([], device=device)\n",
        "    pbar = tqdm.tqdm(trainloader, desc=f'Training epoch: {epoch}', mininterval=2) if log_progress else trainloader\n",
        "    for batch in pbar:\n",
        "      batch = batch.to(device)\n",
        "      pred = model(batch)\n",
        "      loss, predict, truth = loss_func(pred, batch)\n",
        "      prediction = torch.cat([prediction, predict])\n",
        "      ground_truth = torch.cat([ground_truth, truth])\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "\n",
        "def test(model, testloader, loss_func, device):\n",
        "  model.to(device)\n",
        "  ground_truth = torch.Tensor([], device=device)\n",
        "  prediction = torch.Tensor([], device=device)\n",
        "  for batch in tqdm.tqdm(testloader, desc='Testing: ', mininterval=2):\n",
        "    batch = batch.to(device)\n",
        "    pred = model(batch)\n",
        "    loss, p, a = loss_func(pred, batch)\n",
        "    prediction = torch.cat([prediction, p])\n",
        "    ground_truth = torch.cat([ground_truth, a])\n",
        "  auc, recall = performance(ground_truth, prediction)\n",
        "  return auc, recall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cxKU6edGFHoC",
        "outputId": "03bf6e98-1a04-4e1b-f767-2e3199d98642"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting eval.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's get the dataset all loaded up! The dataset is represented as a DataLoader object with a shape of (10217, 50, 248) for the trainset and (2879, 50, 248). The last number represents the input sequence of questions and answers for each student."
      ],
      "metadata": {
        "id": "EZ1B4lIgUGPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from dktmodel import DKTModel\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import eval\n",
        "from dataloader import getDataLoader\n",
        "\n",
        "\"\"\"Defining the parameters\"\"\"\n",
        "max_step = 50\n",
        "batch_size = 64\n",
        "number_of_questions = 124\n",
        "input = number_of_questions * 2\n",
        "hidden = 200\n",
        "layer = 1\n",
        "output = number_of_questions\n",
        "lr = 0.002\n",
        "epochs = 10\n",
        "device = torch.device('cpu')\n",
        "\n",
        "trainloader, testloader = getDataLoader(batch_size, number_of_questions, max_step) \n"
      ],
      "metadata": {
        "id": "zwHHRWQMQBP2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04386bea-5086-4490-c141-a0a3e1a8b30b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading train data...\n",
            "done: (2879, 50, 248)\n",
            "loading test data...\n",
            "done: (10217, 50, 248)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = DKTModel(input,hidden,layer,output,device)\n",
        "loss_func = eval.lossFunc(number_of_questions, max_step, device)\n",
        "eval.train_epoch(model, trainloader, loss_func, device, 1, 10, True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wT6iYntRbkl4",
        "outputId": "b1b4f2b0-5a8e-4757-fd85-99fbe486087e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training from epoch(s) 1 to 10 w/ 45 batches each.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining epoch: 1:   0%|          | 0/45 [00:00<?, ?it/s]/content/eval.py:46: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n",
            "  2)[1:]\n",
            "Training epoch: 1: 100%|██████████| 45/45 [00:05<00:00,  7.62it/s]\n",
            "Training epoch: 2: 100%|██████████| 45/45 [00:05<00:00,  8.21it/s]\n",
            "Training epoch: 3: 100%|██████████| 45/45 [00:05<00:00,  8.10it/s]\n",
            "Training epoch: 4: 100%|██████████| 45/45 [00:05<00:00,  8.04it/s]\n",
            "Training epoch: 5: 100%|██████████| 45/45 [00:05<00:00,  8.13it/s]\n",
            "Training epoch: 6: 100%|██████████| 45/45 [00:05<00:00,  8.13it/s]\n",
            "Training epoch: 7: 100%|██████████| 45/45 [00:05<00:00,  8.19it/s]\n",
            "Training epoch: 8: 100%|██████████| 45/45 [00:05<00:00,  8.20it/s]\n",
            "Training epoch: 9: 100%|██████████| 45/45 [00:05<00:00,  8.20it/s]\n",
            "Training epoch: 10: 100%|██████████| 45/45 [00:05<00:00,  8.08it/s]\n"
          ]
        }
      ]
    }
  ]
}